import streamlit as st
from dotenv import load_dotenv
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.llms.base import LLM
from htmlTemplates import css, bot_template, user_template
from groq import Groq
import os
from typing import Any, List, Mapping, Optional
from pydantic import BaseModel, Field
import time
import pickle

# Load environment variables
load_dotenv()
groq_api_key = os.environ.get("GROQ_API_TOKEN")

class GroqWrapper(LLM, BaseModel):
    client: Groq = Field(default_factory=lambda: Groq(api_key=groq_api_key))
    model_name: str = Field(default="mixtral-8x7b-32768")
    system_prompt: str = Field(default=
        "B·∫°n l√† tr·ª£ l√Ω chuy√™n v·ªÅ l·ªãch s·ª≠ Vi·ªát Nam. \
        B·∫°n cung c·∫•p c√¢u tr·∫£ l·ªùi ch√≠nh x√°c v√† chi ti·∫øt d·ª±a tr√™n n·ªôi dung t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p. \
        N·∫øu kh√¥ng bi·∫øt, b·∫°n s·∫Ω tr·∫£ l·ªùi T√¥i kh√¥ng bi·∫øt. \
        B·∫°n kh√¥ng t·∫°o ra th√¥ng tin sai l·ªách.\
        B·∫°n lu√¥n tr·∫£ l·ªùi t√¥i b·∫±ng ti·∫øng Vi·ªát."
    )

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        try:
            completion = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.5,  # Gi·∫£m temperature ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
                max_tokens=1024,
                top_p=1,
                stream=False,
                stop=stop,
            )
            return completion.choices[0].message.content
        except Exception as e:
            st.error(f"Error during completion: {e}")
            return "ƒê√£ x·∫£y ra l·ªói khi t·∫°o ph·∫£n h·ªìi."

    @property
    def _llm_type(self) -> str:
        return "groq"

    def get_num_tokens(self, text: str) -> int:
        return len(text.split())

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        return {"model_name": self.model_name, "system_prompt": self.system_prompt}

# H√†m t·∫£i vectorstore ƒë√£ l∆∞u
def load_vectorstore(path="vectorstore.pkl"):
    with open(path, "rb") as f:
        vectorstore = pickle.load(f)
    return vectorstore

def get_conversation_chain(vectorstore, system_prompt):
    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)
    
    if not groq_api_key:
        raise ValueError("GROQ_API_TOKEN is not set in the environment variables")

    llm = GroqWrapper(system_prompt=system_prompt)
    st.success(f"Initialized GroqWrapper with model: {llm.model_name}")

    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        memory=memory
    )
    return conversation_chain

def handle_userinput(user_question):
    response = st.session_state.conversation({'question': user_question})
    st.session_state.chat_history = response['chat_history']

    # Th√™m tin nh·∫Øn m·ªõi v√†o danh s√°ch
    new_messages = []
    for message in st.session_state.chat_history[-2:]:  # L·∫•y hai tin nh·∫Øn cu·ªëi
        if message.type == 'human':
            new_messages.append({"role": "user", "content": message.content})
        else:
            new_messages.append({"role": "assistant", "content": message.content})
    
    st.session_state.messages = new_messages + st.session_state.messages

def clear_chat_history():
    st.session_state.messages = []
    st.session_state.chat_history = []

def main():
    st.set_page_config(page_title="PDF Chat Assistant", page_icon="üìö", layout="wide")
    st.write(css, unsafe_allow_html=True)

    # Kh·ªüi t·∫°o session state
    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "vectorstore" not in st.session_state:
        st.session_state.vectorstore = None

    st.header("üìö Chat v·ªõi T√†i li·ªáu PDF c·ªßa b·∫°n")
    
    col1, col2 = st.columns([2, 1])
    
    with col2:
        st.subheader("üîß System Prompt")
        system_prompt = st.text_area(
            "T√πy ch·ªânh h√†nh vi AI:",
            (
                "B·∫°n l√† tr·ª£ l√Ω chuy√™n v·ªÅ l·ªãch s·ª≠ Vi·ªát Nam. \
                B·∫°n cung c·∫•p c√¢u tr·∫£ l·ªùi ch√≠nh x√°c v√† chi ti·∫øt d·ª±a tr√™n n·ªôi dung t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p. \
                N·∫øu kh√¥ng bi·∫øt, b·∫°n s·∫Ω tr·∫£ l·ªùi T√¥i kh√¥ng bi·∫øt. \
                B·∫°n kh√¥ng t·∫°o ra th√¥ng tin sai l·ªách v√† lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."
            ),
            height=150
        )

        # Ki·ªÉm tra xem vectorstore ƒë√£ ƒë∆∞·ª£c t·∫£i ch∆∞a
        if st.session_state.vectorstore is None:
            if os.path.exists("vectorstore.pkl"):
                with st.spinner("ƒêang t·∫£i vectorstore..."):
                    st.session_state.vectorstore = load_vectorstore()
                    st.success("Vectorstore ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")
            else:
                st.error("Vectorstore kh√¥ng t·ªìn t·∫°i. Vui l√≤ng ch·∫°y script ti·ªÅn x·ª≠ l√Ω ƒë·ªÉ t·∫°o vectorstore.")

        if st.button("üßπ X√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán"):
            clear_chat_history()
            st.experimental_rerun()

    with col1:
        st.subheader("üí¨ Giao di·ªán Tr√≤ chuy·ªán")
        user_question = st.text_input("ƒê·∫∑t c√¢u h·ªèi v·ªÅ t√†i li·ªáu c·ªßa b·∫°n:", key="user_input")
        
        if user_question:
            if st.session_state.vectorstore and st.session_state.vectorstore is not None:
                if st.session_state.conversation is None:
                    st.session_state.conversation = get_conversation_chain(st.session_state.vectorstore, system_prompt)
                with st.spinner("AI ƒëang suy nghƒ©..."):
                    handle_userinput(user_question)
            else:
                st.warning("Vectorstore ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ki·ªÉm tra l·∫°i.")

        # Hi·ªÉn th·ªã tin nh·∫Øn tr√≤ chuy·ªán
        for message in st.session_state.messages:
            if message["role"] == "user":
                st.markdown(user_template.replace("{{MSG}}", message["content"]), unsafe_allow_html=True)
            else:
                st.markdown(bot_template.replace("{{MSG}}", message["content"]), unsafe_allow_html=True)

if __name__ == '__main__':
    main()
